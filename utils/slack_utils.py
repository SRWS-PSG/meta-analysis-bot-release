import asyncio # upload_files_to_slack ã®ãŸã‚ã«è¿½åŠ 
import os # upload_files_to_slack ã®ãŸã‚ã«è¿½åŠ 
import requests # upload_files_to_slack ã®ãŸã‚ã«è¿½åŠ 
import logging # upload_files_to_slack ã®ãŸã‚ã«è¿½åŠ 
from typing import Dict, Any, List, Optional

logger = logging.getLogger(__name__) # upload_files_to_slack ã®ãŸã‚ã«è¿½åŠ 

def create_analysis_start_message(analysis_result: Dict[str, Any], initial_params: Optional[Dict[str, Any]] = None) -> str:
    """CSVåˆ†æçµæœã‚’è‡ªç„¶è¨€èªãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¨ã—ã¦ä½œæˆï¼ˆButton UIå‰Šé™¤ï¼‰"""
    detected_cols = analysis_result.get("detected_columns", {})
    
    # å„ç¨®ãƒ‡ãƒ¼ã‚¿ã‚¿ã‚¤ãƒ—ã®åˆ—å€™è£œã‚’å–å¾—
    effect_candidates = detected_cols.get("effect_size_candidates", [])
    variance_candidates = detected_cols.get("variance_candidates", [])
    binary_intervention_events = detected_cols.get("binary_intervention_events", [])
    binary_control_events = detected_cols.get("binary_control_events", [])
    continuous_intervention_mean = detected_cols.get("continuous_intervention_mean", [])
    continuous_control_mean = detected_cols.get("continuous_control_mean", [])
    proportion_events = detected_cols.get("proportion_events", [])
    proportion_total = detected_cols.get("proportion_total", [])
    study_id_candidates = detected_cols.get("study_id_candidates", [])
    subgroup_candidates = detected_cols.get("subgroup_candidates", [])
    moderator_candidates = detected_cols.get("moderator_candidates", [])
    
    # è¡¨ç¤ºç”¨ã®å€™è£œã‚’æ§‹ç¯‰
    data_type_info = []
    
    # äº‹å‰è¨ˆç®—æ¸ˆã¿åŠ¹æœé‡ãƒ‡ãƒ¼ã‚¿
    if effect_candidates:
        data_type_info.append(f"äº‹å‰è¨ˆç®—æ¸ˆã¿åŠ¹æœé‡: {', '.join(effect_candidates[:2])}")
    
    # äºŒå€¤ã‚¢ã‚¦ãƒˆã‚«ãƒ ãƒ‡ãƒ¼ã‚¿
    binary_candidates = []
    if binary_intervention_events:
        binary_candidates.extend(binary_intervention_events[:1])
    if binary_control_events:
        binary_candidates.extend(binary_control_events[:1])
    
    # ç·æ•°åˆ—ã‚‚å«ã‚ã‚‹
    binary_total_info = []
    binary_intervention_total = detected_cols.get("binary_intervention_total", [])
    binary_control_total = detected_cols.get("binary_control_total", [])
    if binary_intervention_total:
        binary_total_info.extend(binary_intervention_total[:1])
    if binary_control_total:
        binary_total_info.extend(binary_control_total[:1])
    
    if binary_candidates:
        display_text = f"äºŒå€¤ã‚¢ã‚¦ãƒˆã‚«ãƒ : {', '.join(binary_candidates)}"
        if binary_total_info:
            display_text += f" (ç·æ•°: {', '.join(binary_total_info)})"
        data_type_info.append(display_text)
    
    # é€£ç¶šã‚¢ã‚¦ãƒˆã‚«ãƒ ãƒ‡ãƒ¼ã‚¿
    continuous_candidates = []
    if continuous_intervention_mean:
        continuous_candidates.extend(continuous_intervention_mean[:1])
    if continuous_control_mean:
        continuous_candidates.extend(continuous_control_mean[:1])
    if continuous_candidates:
        data_type_info.append(f"é€£ç¶šã‚¢ã‚¦ãƒˆã‚«ãƒ : {', '.join(continuous_candidates)}")
    
    # å˜ä¸€ç¾¤æ¯”ç‡ãƒ‡ãƒ¼ã‚¿
    proportion_candidates = []
    if proportion_events:
        proportion_candidates.extend(proportion_events[:1])
    if proportion_total:
        proportion_candidates.extend(proportion_total[:1])
    if proportion_candidates:
        data_type_info.append(f"å˜ä¸€ç¾¤æ¯”ç‡: {', '.join(proportion_candidates)}")
    
    # è¡¨ç¤ºç”¨æ–‡å­—åˆ—ã®ä½œæˆ
    effect_display = "; ".join(data_type_info) if data_type_info else "æ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ"
    variance_display = ", ".join(variance_candidates[:3]) if variance_candidates else "æ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ"
    study_id_display = ", ".join(study_id_candidates[:2]) if study_id_candidates else "æ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ"
    subgroup_display = ", ".join(subgroup_candidates[:5]) if subgroup_candidates else "æ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ"
    moderator_display = ", ".join(moderator_candidates[:5]) if moderator_candidates else "æ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ"

    suggested_analysis = analysis_result.get("suggested_analysis", {})
    suggested_effect_type = suggested_analysis.get("effect_type_suggestion", "æœªæ¤œå‡º")
    suggested_model_type = suggested_analysis.get("model_type_suggestion", "æœªæ¤œå‡º")
    
    # é…åˆ—ã¨ã—ã¦è¿”ã•ã‚Œã‚‹å ´åˆã®å‡¦ç†
    if isinstance(suggested_effect_type, list):
        suggested_effect_type = ", ".join(suggested_effect_type) if suggested_effect_type else "æœªæ¤œå‡º"
    if isinstance(suggested_model_type, list):
        suggested_model_type = ", ".join(suggested_model_type) if suggested_model_type else "æœªæ¤œå‡º"
    
    # ç ”ç©¶æ•°ã‚’å–å¾—ï¼ˆGeminiãŒè¿”ã™num_studiesãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’å„ªå…ˆï¼‰
    num_studies = analysis_result.get("num_studies", "ä¸æ˜")
    if num_studies == "ä¸æ˜":
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: reasonã‹ã‚‰æŠ½å‡ºã‚’è©¦ã¿ã‚‹
        reason = analysis_result.get("reason", "")
        import re
        study_count_match = re.search(r'(\d+)ä»¶?ã®?ç ”ç©¶', reason)
        if study_count_match:
            num_studies = study_count_match.group(1)
        else:
            data_preview = analysis_result.get("data_preview", [])
            num_studies = f"{len(data_preview)}+ (ã‚µãƒ³ãƒ—ãƒ«è¡¨ç¤º)" if data_preview else "ä¸æ˜"
    
    # åˆæœŸãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®è¡¨ç¤º
    auto_detected_params = ""
    if initial_params:
        auto_params = []
        if initial_params.get("effect_size"):
            auto_params.append(f"åŠ¹æœé‡: {initial_params['effect_size']}")
        if initial_params.get("model_type"):
            auto_params.append(f"ãƒ¢ãƒ‡ãƒ«: {initial_params['model_type']}")
        if initial_params.get("study_column"):
            auto_params.append(f"ç ”ç©¶IDåˆ—: {initial_params['study_column']}")
        
        if auto_params:
            auto_detected_params = f"\n\n**ğŸ¤– è‡ªå‹•æ¤œå‡ºæ¸ˆã¿ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿:**\nâ€¢ " + "\nâ€¢ ".join(auto_params)
    
    # äº‹å‰è¨ˆç®—æ¸ˆã¿åŠ¹æœé‡ã¨ã—ã¦æ¤œå‡ºã•ã‚ŒãŸå ´åˆã®ç¢ºèªãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
    confirmation_message = ""
    if effect_candidates and not binary_candidates and not continuous_candidates:
        # äº‹å‰è¨ˆç®—æ¸ˆã¿åŠ¹æœé‡ã®ã¿ãŒæ¤œå‡ºã•ã‚ŒãŸå ´åˆ
        confirmation_message = f"\n\n**â“ ç¢ºèªäº‹é …:**\næ¤œå‡ºã•ã‚ŒãŸåˆ— ({', '.join(effect_candidates[:2])}) ã¯äº‹å‰è¨ˆç®—æ¸ˆã¿ã®åŠ¹æœé‡ã§ã—ã‚‡ã†ã‹ï¼Ÿ\nâ€¢ ã¯ã„ â†’ ãã®ã¾ã¾è§£æã‚’ç¶šè¡Œã—ã¾ã™\nâ€¢ ã„ã„ãˆ â†’ äºŒå€¤ã‚¢ã‚¦ãƒˆã‚«ãƒ ï¼ˆOR/RRç­‰ï¼‰ã¨ã—ã¦æ‰±ã„ã¾ã™"
    
    message = f"""ğŸ“Š **CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’åˆ†æã—ã¾ã—ãŸï¼**

**ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæ¦‚è¦:**
â€¢ ç ”ç©¶æ•°: {num_studies}ä»¶
â€¢ æ¤œå‡ºãƒ‡ãƒ¼ã‚¿: {effect_display}
â€¢ åˆ†æ•£/SEå€™è£œåˆ—: {variance_display}
â€¢ ç ”ç©¶IDå€™è£œåˆ—: {study_id_display}
â€¢ ã‚µãƒ–ã‚°ãƒ«ãƒ¼ãƒ—å€™è£œåˆ—: {subgroup_display}
â€¢ ãƒ¡ã‚¿å›å¸°å€™è£œåˆ—: {moderator_display}
â€¢ æ¨å¥¨åŠ¹æœé‡: {suggested_effect_type}
â€¢ æ¨å¥¨ãƒ¢ãƒ‡ãƒ«: {suggested_model_type}{auto_detected_params}{confirmation_message}

**è§£æãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æ•™ãˆã¦ãã ã•ã„ã€‚**

ä¾‹ï¼š
â€¢ ã€Œã‚ªãƒƒã‚ºæ¯”ã§ãƒ©ãƒ³ãƒ€ãƒ åŠ¹æœãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ã£ã¦è§£æã—ã¦ã€
â€¢ ã€ŒSMDã§REMLæ³•ã‚’ä½¿ã£ã¦ã€åœ°åŸŸåˆ¥ã®ã‚µãƒ–ã‚°ãƒ«ãƒ¼ãƒ—è§£æã‚‚è¡Œã£ã¦ã€
â€¢ ã€Œã“ã®ã¾ã¾è§£æé–‹å§‹ã€ï¼ˆè‡ªå‹•æ¤œå‡ºæ¸ˆã¿ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ï¼‰

ã©ã®ã‚ˆã†ãªè§£æã‚’ã”å¸Œæœ›ã§ã™ã‹ï¼Ÿ"""

    return message

def create_unsuitable_csv_message(reason: str) -> str:
    """ãƒ¡ã‚¿è§£æã«é©ã•ãªã„CSVã®å ´åˆã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ä½œæˆ"""
    return f"""âŒ **ãƒ¡ã‚¿è§£æã«ä¸é©åˆãªCSVãƒ•ã‚¡ã‚¤ãƒ«**

ç†ç”±: {reason}

åˆ¥ã®CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã‹ã€ãƒ•ã‚¡ã‚¤ãƒ«ã®å†…å®¹ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚

å¿…è¦ãªåˆ—ã®ä¾‹ï¼š
â€¢ åŠ¹æœé‡ã¨ãã®æ¨™æº–èª¤å·®
â€¢ äºŒå€¤ã‚¢ã‚¦ãƒˆã‚«ãƒ ã®å ´åˆï¼šã‚¤ãƒ™ãƒ³ãƒˆæ•°ã¨ã‚µãƒ³ãƒ—ãƒ«ã‚µã‚¤ã‚º
â€¢ é€£ç¶šã‚¢ã‚¦ãƒˆã‚«ãƒ ã®å ´åˆï¼šå¹³å‡å€¤ã€æ¨™æº–åå·®ã€ã‚µãƒ³ãƒ—ãƒ«ã‚µã‚¤ã‚º

ã”ä¸æ˜ãªç‚¹ãŒã‚ã‚Œã°ã€ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’ãŠé€ã‚Šãã ã•ã„ã€‚"""

# Button UIã‚’å‰Šé™¤ã—ã€è‡ªç„¶è¨€èªå¯¾è©±ã«çµ±ä¸€
# create_simple_parameter_selection_blocksã¯å‰Šé™¤ï¼ˆCLAUDE.mdã®è¦ä»¶ã«å¾“ã„è‡ªç„¶è¨€èªå¯¾è©±ã®ã¿ï¼‰

def create_analysis_result_message(analysis_result_from_r: Dict[str, Any]) -> str:
    """è§£æçµæœã‚’è‡ªç„¶è¨€èªãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¨ã—ã¦ä½œæˆ"""
    summary = analysis_result_from_r.get("summary", {})
    
    # R script generates: estimate, ci_lb, ci_ub, I2, k
    pooled_effect = summary.get('estimate', 'N/A')
    ci_lower = summary.get('ci_lb', 'N/A')
    ci_upper = summary.get('ci_ub', 'N/A') 
    i2_value = summary.get('I2', 'N/A')
    num_studies = summary.get('k', 'N/A')
    
    # Format numeric values
    if isinstance(pooled_effect, (int, float)):
        pooled_effect = f"{pooled_effect:.3f}"
    if isinstance(ci_lower, (int, float)):
        ci_lower = f"{ci_lower:.3f}"
    if isinstance(ci_upper, (int, float)):
        ci_upper = f"{ci_upper:.3f}"
    if isinstance(i2_value, (int, float)):
        i2_value = f"{i2_value:.1f}"
    
    # ã‚µãƒ–ã‚°ãƒ«ãƒ¼ãƒ—è§£æçµæœã‚’è¿½åŠ 
    subgroup_text = ""
    for key, value in summary.items():
        if key.startswith('subgroup_moderation_test_'):
            subgroup_var = key.replace('subgroup_moderation_test_', '')
            if isinstance(value, dict):
                qm_p = value.get('QMp', 'N/A')
                if isinstance(qm_p, (int, float)):
                    qm_p = f"{qm_p:.3f}"
                subgroup_text += f"\nâ€¢ {subgroup_var}åˆ¥ã‚µãƒ–ã‚°ãƒ«ãƒ¼ãƒ—è§£æ: p={qm_p}"
        
        elif key.startswith('subgroup_analyses_'):
            subgroup_var = key.replace('subgroup_analyses_', '')
            if isinstance(value, dict):
                subgroup_text += f"\n\n**ã€{subgroup_var}åˆ¥ã‚µãƒ–ã‚°ãƒ«ãƒ¼ãƒ—çµæœã€‘**"
                for level_name, level_result in value.items():
                    if isinstance(level_result, dict):
                        sg_estimate = level_result.get('estimate', 'N/A')
                        sg_ci_lb = level_result.get('ci_lb', 'N/A')
                        sg_ci_ub = level_result.get('ci_ub', 'N/A')
                        sg_k = level_result.get('k', 'N/A')
                        
                        if isinstance(sg_estimate, (int, float)):
                            sg_estimate = f"{sg_estimate:.3f}"
                        if isinstance(sg_ci_lb, (int, float)):
                            sg_ci_lb = f"{sg_ci_lb:.3f}"
                        if isinstance(sg_ci_ub, (int, float)):
                            sg_ci_ub = f"{sg_ci_ub:.3f}"
                        
                        subgroup_text += f"\nâ€¢ {level_name}: åŠ¹æœé‡={sg_estimate} [{sg_ci_lb}, {sg_ci_ub}] (k={sg_k})"
    
    # ã‚¼ãƒ­ã‚»ãƒ«è§£æçµæœã‚’è¿½åŠ 
    zero_cell_text = ""
    zero_cells_summary = summary.get('zero_cells_summary')
    
    # DEBUG: Log summary structure
    import logging
    logger = logging.getLogger(__name__)
    logger.info(f"DEBUG: Full summary keys: {list(summary.keys())}")
    logger.info(f"DEBUG: zero_cells_summary: {zero_cells_summary}")
    
    if zero_cells_summary:
        studies_with_zero = zero_cells_summary.get('studies_with_zero_cells', 0)
        logger.info(f"DEBUG: studies_with_zero: {studies_with_zero}")
        if studies_with_zero > 0:
            double_zero = zero_cells_summary.get('double_zero_studies', 0)
            intervention_zero = zero_cells_summary.get('intervention_zero_studies', 0)
            control_zero = zero_cells_summary.get('control_zero_studies', 0)
            main_method = summary.get('main_analysis_method', 'N/A')
            
            zero_cell_text = f"\n\n**ã€ã‚¼ãƒ­ã‚»ãƒ«å¯¾å¿œã€‘**"
            zero_cell_text += f"\nâ€¢ ã‚¼ãƒ­ã‚»ãƒ«ã‚’å«ã‚€ç ”ç©¶æ•°: {studies_with_zero}ä»¶"
            if double_zero > 0:
                zero_cell_text += f"\nâ€¢ ä¸¡ç¾¤ã‚¼ãƒ­ç ”ç©¶æ•°: {double_zero}ä»¶"
            if intervention_zero > 0:
                zero_cell_text += f"\nâ€¢ ä»‹å…¥ç¾¤ã‚¼ãƒ­ç ”ç©¶æ•°: {intervention_zero}ä»¶"
            if control_zero > 0:
                zero_cell_text += f"\nâ€¢ å¯¾ç…§ç¾¤ã‚¼ãƒ­ç ”ç©¶æ•°: {control_zero}ä»¶"
            zero_cell_text += f"\nâ€¢ ä¸»è§£ææ‰‹æ³•: {main_method}"
            
            # æ„Ÿåº¦è§£æçµæœã‚’è¿½åŠ 
            sensitivity_results = summary.get('sensitivity_analysis', {})
            if sensitivity_results:
                zero_cell_text += f"\nâ€¢ æ„Ÿåº¦è§£æã‚‚å®Ÿè¡Œï¼ˆè©³ç´°ã¯Rã‚¹ã‚¯ãƒªãƒ—ãƒˆå‚ç…§ï¼‰"

    # ãƒ¡ã‚¿å›å¸°çµæœã‚’è¿½åŠ 
    meta_regression_text = ""
    meta_regression_results = summary.get('meta_regression_results')
    if meta_regression_results:
        qm_p = meta_regression_results.get('QMp', 'N/A')
        if isinstance(qm_p, (int, float)):
            qm_p = f"{qm_p:.3f}"
        meta_regression_text = f"\nâ€¢ ãƒ¡ã‚¿å›å¸°åˆ†æ: p={qm_p}"
        
        moderators = meta_regression_results.get('moderators', {})
        if moderators:
            meta_regression_text += f"\n\n**ã€ãƒ¡ã‚¿å›å¸°çµæœã€‘**"
            for mod_name, mod_result in moderators.items():
                if isinstance(mod_result, dict):
                    mod_estimate = mod_result.get('estimate', 'N/A')
                    mod_pval = mod_result.get('pval', 'N/A')
                    
                    if isinstance(mod_estimate, (int, float)):
                        mod_estimate = f"{mod_estimate:.3f}"
                    if isinstance(mod_pval, (int, float)):
                        mod_pval = f"{mod_pval:.3f}"
                    
                    meta_regression_text += f"\nâ€¢ {mod_name}: ä¿‚æ•°={mod_estimate}, p={mod_pval}"
    
    message = f"""ğŸ“Š **ãƒ¡ã‚¿è§£æãŒå®Œäº†ã—ã¾ã—ãŸï¼**

**ã€è§£æçµæœã‚µãƒãƒªãƒ¼ã€‘**
â€¢ çµ±åˆåŠ¹æœé‡: {pooled_effect}
â€¢ 95%ä¿¡é ¼åŒºé–“: {ci_lower} - {ci_upper}
â€¢ ç•°è³ªæ€§: IÂ²={i2_value}%
â€¢ ç ”ç©¶æ•°: {num_studies}ä»¶{zero_cell_text}{subgroup_text}{meta_regression_text}

ãƒ•ã‚¡ã‚¤ãƒ«ãŒæ·»ä»˜ã•ã‚Œã¦ã„ã¾ã™ï¼š
â€¢ ãƒ•ã‚©ãƒ¬ã‚¹ãƒˆãƒ—ãƒ­ãƒƒãƒˆ
â€¢ Rã‚¹ã‚¯ãƒªãƒ—ãƒˆ
â€¢ è§£æçµæœãƒ‡ãƒ¼ã‚¿

è§£é‡ˆãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆä¸­ã§ã™..."""
    
    return message

def create_report_message(interpretation: Dict[str, Any]) -> str:
    """è§£é‡ˆãƒ¬ãƒãƒ¼ãƒˆã‚’è‡ªç„¶è¨€èªãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¨ã—ã¦ä½œæˆï¼ˆçµ±è¨ˆè§£æã¨GRADEæº–æ‹ çµæœã®ã¿ï¼‰"""
    methods_text = interpretation.get('methods_section', 'N/A')
    results_text = interpretation.get('results_section', 'N/A')
    summary_text = interpretation.get('summary', 'N/A')

    message = f"""ğŸ“„ **è§£é‡ˆãƒ¬ãƒãƒ¼ãƒˆï¼ˆå­¦è¡“è«–æ–‡å½¢å¼ï¼‰**

**ã€è¦ç´„ã€‘**
{summary_text}

**ã€çµ±è¨ˆè§£æ / Statistical Analysisã€‘**
{methods_text[:1200]}{'...' if len(methods_text) > 1200 else ''}

**ã€çµæœ / Resultsã€‘**
{results_text[:1200]}{'...' if len(results_text) > 1200 else ''}

---
*ã“ã®ãƒ¬ãƒãƒ¼ãƒˆã¯AIã«ã‚ˆã£ã¦ç”Ÿæˆã•ã‚Œã¾ã—ãŸã€‚çµ±è¨ˆè§£æçµæœã®ã¿ã‚’è¨˜è¼‰ã—ã¦ã„ã¾ã™ã€‚*"""
    
    return message

# create_parameter_modal_blocksã‚‚å‰Šé™¤ï¼ˆè‡ªç„¶è¨€èªå¯¾è©±ã«çµ±ä¸€ï¼‰

async def upload_files_to_slack(files_to_upload: List[Dict[str, str]], channel_id: str, thread_ts: Optional[str], client: Any, job_id: str) -> List[Dict[str, Any]]:
    """
    æŒ‡å®šã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒªã‚¹ãƒˆã‚’Slackã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã€‚
    files_to_upload: [{"type": "file_type", "path": "/path/to/file", "title": "File Title"}, ...]
    """
    uploaded_file_infos = []
    if not files_to_upload:
        return uploaded_file_infos

    for file_info in files_to_upload:
        file_path = file_info.get("path")
        file_title = file_info.get("title", os.path.basename(file_path) if file_path else "Untitled")
        file_type_label = file_info.get("type", "file") # ä¾‹: forest_plot, summary_json

        if not file_path or not os.path.exists(file_path):
            logger.warning(f"ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚‰ãªã„ãŸã‚ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã‚’ã‚¹ã‚­ãƒƒãƒ—: {file_path} (Job ID: {job_id})")
            continue

        try:
            # Slack SDKã® files_upload_v2 ã‚’ä½¿ç”¨ï¼ˆfileãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§æŒ‡å®šï¼‰
            response = await asyncio.to_thread(
                client.files_upload_v2,
                channel=channel_id,
                file=file_path,
                title=file_title,
                initial_comment=f"{file_title} ({job_id})",
                thread_ts=thread_ts
            )
            if response.get("ok") and response.get("file"):
                slack_file_info = response["file"]
                uploaded_file_infos.append({
                    "type": file_type_label,
                    "id": slack_file_info.get("id"),
                    "name": slack_file_info.get("name"),
                    "url_private_download": slack_file_info.get("url_private_download"),
                    "permalink": slack_file_info.get("permalink"),
                    "title": file_title # å…ƒã®ã‚¿ã‚¤ãƒˆãƒ«ã‚‚ä¿æŒ
                })
                logger.info(f"ãƒ•ã‚¡ã‚¤ãƒ« '{file_title}' ã‚’Slackã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æˆåŠŸ (File ID: {slack_file_info.get('id')}, Job ID: {job_id})")
            else:
                logger.error(f"ãƒ•ã‚¡ã‚¤ãƒ« '{file_title}' ã®Slackã¸ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã«å¤±æ•—ã€‚Response: {response} (Job ID: {job_id})")
        except Exception as e:
            logger.error(f"ãƒ•ã‚¡ã‚¤ãƒ« '{file_title}' ã®Slackã¸ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ä¸­ã«ä¾‹å¤–ç™ºç”Ÿ: {e} (Job ID: {job_id})")
            # å€‹ã€…ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å¤±æ•—ã¯å…¨ä½“ã‚’æ­¢ã‚ãªã„
    
    return uploaded_file_infos

def upload_file_to_slack(client, file_path, channel_id, title, thread_ts=None):
    """æ–°ã—ã„files.getUploadURLExternal APIã‚’ä½¿ç”¨ã—ã¦ãƒ•ã‚¡ã‚¤ãƒ«ã‚’Slackã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã™ã‚‹"""
    try:
        get_url_response = client.files_getUploadURLExternal(
            filename=os.path.basename(file_path),
            length=os.path.getsize(file_path),
        )
    except Exception as e:
        logger.error(f"files.getUploadURLExternalã®å‘¼ã³å‡ºã—ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
        raise

    with open(file_path, 'rb') as f:
        file_content = f.read()
    
    try:
        upload_response = requests.post(
            get_url_response["upload_url"],
            data=file_content,
            headers={"Content-Type": "application/octet-stream"},
            allow_redirects=True
        )
        upload_response.raise_for_status()
    except Exception as e:
        logger.error(f"ãƒ•ã‚¡ã‚¤ãƒ«ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
        raise
        
    files_data = [{
        "id": get_url_response["file_id"],
        "title": title,
    }]

    try:
        complete_response = client.files_completeUploadExternal(
            files=files_data,
            channel_id=channel_id,
            thread_ts=thread_ts,
            initial_comment=f"{title}ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¾ã—ãŸã€‚"
        )
        return complete_response
    except Exception as e:
        logger.error(f"files.completeUploadExternalã®å‘¼ã³å‡ºã—ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
        # Attempt to delete the file if completion fails to avoid orphaned uploads
        try:
            client.files_delete(file=get_url_response["file_id"])
            logger.info(f"ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å®Œäº†å¤±æ•—å¾Œã€ãƒ•ã‚¡ã‚¤ãƒ« {get_url_response['file_id']} ã‚’å‰Šé™¤ã—ã¾ã—ãŸã€‚")
        except Exception as delete_e:
            logger.error(f"ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å®Œäº†å¤±æ•—å¾Œã®ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤ä¸­ã«ã‚¨ãƒ©ãƒ¼: {delete_e}")
        raise
